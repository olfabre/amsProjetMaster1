{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olfabre/amsProjetMaster1/blob/olivier/Generation_prenoms_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import unidecode\n",
        "except ModuleNotFoundError:\n",
        "    !pip install unidecode\n",
        "    import unidecode\n",
        "\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Vérification GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Appareil utilisé : {device}\")\n",
        "\n",
        "# Téléchargement des données\n",
        "url = \"https://olivier-fabre.com/passwordgenius/russian.txt\"\n",
        "data_dir = \"data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "data_path = os.path.join(data_dir, \"russian.txt\")\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "    print(\"Téléchargement des données...\")\n",
        "    response = requests.get(url)\n",
        "    with open(data_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(response.text)\n",
        "\n",
        "# Chargement des données\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unidecode.unidecode(s)\n",
        "        if c in (string.ascii_letters + \" .,;'-\")\n",
        "    )\n",
        "\n",
        "def read_lines(filename):\n",
        "    with open(filename, encoding='utf-8') as f:\n",
        "        return [unicode_to_ascii(line.strip().lower()) for line in f]\n",
        "\n",
        "lines = read_lines(data_path)\n",
        "print(f\"Nombre de prénoms : {len(lines)}\")\n",
        "\n",
        "# Division des données\n",
        "random.shuffle(lines)\n",
        "train_split = int(0.8 * len(lines))\n",
        "valid_split = int(0.1 * len(lines))\n",
        "train_lines = lines[:train_split]\n",
        "valid_lines = lines[train_split:train_split + valid_split]\n",
        "test_lines = lines[train_split + valid_split:]\n",
        "print(f\"Ensemble d'entraînement : {len(train_lines)}, Validation : {len(valid_lines)}, Test : {len(test_lines)}\")\n",
        "\n",
        "# Paramètres globaux\n",
        "all_letters = string.ascii_letters + \" .,;'-\"\n",
        "n_letters = len(all_letters) + 1  # EOS marker\n",
        "bidirectional = True\n",
        "max_length = 20\n",
        "\n",
        "\n",
        "# Optimisation des paramètres et hyperparamètres\n",
        "hidden_size = 256  # Augmentation de la taille cachée pour un meilleur apprentissage\n",
        "n_layers = 3  # Augmentation du nombre de couches cachées\n",
        "lr = 0.003  # Ajustement du taux d'apprentissage\n",
        "n_epochs = 200000  # Nombre d'époques augmenté\n",
        "\n",
        "\n",
        "# Fonctions utilitaires\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_letters.index(string[c])\n",
        "    return tensor\n",
        "\n",
        "def input_tensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li in range(len(line)):\n",
        "        letter = line[li]\n",
        "        tensor[li][0][all_letters.find(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "def target_tensor(line):\n",
        "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
        "    letter_indexes.append(n_letters - 1)  # EOS\n",
        "    return torch.LongTensor(letter_indexes)\n",
        "\n",
        "def random_training_example(lines):\n",
        "    line = random.choice(lines)\n",
        "    input_line_tensor = input_tensor(line)\n",
        "    target_line_tensor = target_tensor(line)\n",
        "    return input_line_tensor, target_line_tensor\n",
        "\n",
        "# Fonction pour afficher le temps écoulé\n",
        "def time_since(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f\"{m}m {s:.2f}s\"\n",
        "\n",
        "# Définition du modèle\n",
        "class RNNLight(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNNLight, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 2 if self.bidirectional else 1\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=input_size, hidden_size=hidden_size,\n",
        "            num_layers=1, bidirectional=self.bidirectional, batch_first=True\n",
        "        )\n",
        "        self.out = nn.Linear(self.num_directions * hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        _, hidden = self.rnn(input.unsqueeze(0), hidden)\n",
        "        hidden_concat = hidden if not self.bidirectional else torch.cat((hidden[0], hidden[1]), 1)\n",
        "        output = self.out(hidden_concat)\n",
        "        output = self.dropout(output)\n",
        "        return self.softmax(output), hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.num_directions, 1, self.hidden_size, device=device)\n",
        "\n",
        "# Entraînement avec sauvegarde\n",
        "def train(input_line_tensor, target_line_tensor, decoder, decoder_optimizer, criterion):\n",
        "    target_line_tensor = target_line_tensor.to(device)\n",
        "    hidden = decoder.init_hidden().to(device)\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "    correct = 0  # Pour calculer la précision\n",
        "    total = target_line_tensor.size(0)\n",
        "\n",
        "    for i in range(input_line_tensor.size(0)):\n",
        "        input_tensor = input_line_tensor[i].to(device)\n",
        "        target_tensor = target_line_tensor[i].unsqueeze(0).to(device)\n",
        "        output, hidden = decoder(input_tensor, hidden.detach())\n",
        "        l = criterion(output, target_tensor)\n",
        "        loss += l\n",
        "\n",
        "        # Calcul de la précision\n",
        "        predicted = output.topk(1)[1][0][0]\n",
        "        correct += (predicted == target_tensor[0]).item()\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return loss.item() / input_line_tensor.size(0), accuracy\n",
        "\n",
        "def validation(input_line_tensor, target_line_tensor, decoder, criterion):\n",
        "    with torch.no_grad():\n",
        "        target_line_tensor = target_line_tensor.to(device)\n",
        "        hidden = decoder.init_hidden().to(device)\n",
        "        loss = 0\n",
        "        correct = 0  # Pour calculer la précision\n",
        "        total = target_line_tensor.size(0)\n",
        "\n",
        "        for i in range(input_line_tensor.size(0)):\n",
        "            input_tensor = input_line_tensor[i].to(device)\n",
        "            target_tensor = target_line_tensor[i].unsqueeze(0).to(device)\n",
        "            output, hidden = decoder(input_tensor, hidden.detach())\n",
        "            l = criterion(output, target_tensor)\n",
        "            loss += l\n",
        "\n",
        "            # Calcul de la précision\n",
        "            predicted = output.topk(1)[1][0][0]\n",
        "            correct += (predicted == target_tensor[0]).item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        return loss.item() / input_line_tensor.size(0), accuracy\n",
        "\n",
        "def training(n_epochs, train_lines, valid_lines, decoder, decoder_optimizer, criterion):\n",
        "    print(\"\\n-----------\\n|  ENTRAÎNEMENT  |\\n-----------\\n\")\n",
        "    start = time.time()\n",
        "    best_loss = float(\"inf\")\n",
        "    model_path = \"best_model_generation_prenom.pth\"\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        # Entraînement\n",
        "        input_line_tensor, target_line_tensor = random_training_example(train_lines)\n",
        "        train_loss, train_acc = train(input_line_tensor, target_line_tensor, decoder, decoder_optimizer, criterion)\n",
        "\n",
        "        # Validation\n",
        "        input_line_tensor, target_line_tensor = random_training_example(valid_lines)\n",
        "        val_loss, val_acc = validation(input_line_tensor, target_line_tensor, decoder, criterion)\n",
        "\n",
        "        # Sauvegarde du meilleur modèle\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save(decoder.state_dict(), model_path)\n",
        "            print(f\"\\nÉpoch {epoch} : La perte de validation a diminué à {best_loss:.4f}. Modèle sauvegardé.\")\n",
        "            print(f\"Précision de validation : {val_acc:.4f}\")\n",
        "            generate_series(decoder)\n",
        "\n",
        "        if epoch % 500 == 0 or epoch == 1:\n",
        "            print(f\"{time_since(start)} Époch {epoch}/{n_epochs}, Perte entraînement : {train_loss:.4f}, Précision entraînement : {train_acc:.4f}\")\n",
        "            print(f\"Perte validation : {val_loss:.4f}, Précision validation : {val_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Exécution principale\n",
        "if __name__ == \"__main__\":\n",
        "    decoder = RNNLight(n_letters, hidden_size, n_letters).to(device)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"Démarrage de l'entraînement...\")\n",
        "    training(n_epochs, train_lines, valid_lines, decoder, decoder_optimizer, criterion)\n",
        "\n",
        "    print(\"\\nGénération finale de prénoms :\")\n",
        "    generate_series(decoder, start_letters=\"JKLMNOP\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-OY1QlZ5sDGl",
        "outputId": "abd80c40-5073-4df4-e4c4-6f60dda96b96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appareil utilisé : cuda:0\n",
            "Nombre de prénoms : 9408\n",
            "Ensemble d'entraînement : 7526, Validation : 940, Test : 942\n",
            "Démarrage de l'entraînement...\n",
            "\n",
            "-----------\n",
            "|  ENTRAÎNEMENT  |\n",
            "-----------\n",
            "\n",
            "\n",
            "Époch 1 : La perte de validation a diminué à 4.0321. Modèle sauvegardé.\n",
            "Précision de validation : 0.0000\n",
            "Prénoms générés :\n",
            "- Amemetdisometddioovea\n",
            "- Bmsametdinoveametdiov\n",
            "- Cmmeadisometdisometdi\n",
            "- Dmmetdisometdisametdi\n",
            "- Emsamametdisometdisom\n",
            "0m 0.08s Époch 1/200000, Perte entraînement : 4.0573, Précision entraînement : 0.1667\n",
            "Perte validation : 4.0321, Précision validation : 0.0000\n",
            "\n",
            "Époch 2 : La perte de validation a diminué à 3.9900. Modèle sauvegardé.\n",
            "Précision de validation : 0.0000\n",
            "Prénoms générés :\n",
            "- Amsssessisessinesessi\n",
            "- Bisasetsinessisesessi\n",
            "- Cmsssessisesessisessi\n",
            "- Dssseetsessisessisess\n",
            "- Eisasessisesessisessi\n",
            "\n",
            "Époch 3 : La perte de validation a diminué à 3.7434. Modèle sauvegardé.\n",
            "Précision de validation : 0.0000\n",
            "Prénoms générés :\n",
            "- Aseseeesiseeeeeeeeeee\n",
            "- Biseseeeeseseeeeeeeee\n",
            "- Ciseeeeeeesseeeeeeeee\n",
            "- Dsseseeeeeeeeeeeeeeee\n",
            "- Eieeseseeseeeeeeeeeee\n",
            "\n",
            "Époch 5 : La perte de validation a diminué à 3.0542. Modèle sauvegardé.\n",
            "Précision de validation : 0.2857\n",
            "Prénoms générés :\n",
            "- Asss\n",
            "- Bis\n",
            "- Csss\n",
            "- Diss\n",
            "- Eiss\n",
            "\n",
            "Époch 18 : La perte de validation a diminué à 2.8448. Modèle sauvegardé.\n",
            "Précision de validation : 0.1667\n",
            "Prénoms générés :\n",
            "- Aiii\n",
            "- Bei\n",
            "- Ciii\n",
            "- Diii\n",
            "- Eiii\n",
            "\n",
            "Époch 26 : La perte de validation a diminué à 2.6130. Modèle sauvegardé.\n",
            "Précision de validation : 0.2500\n",
            "Prénoms générés :\n",
            "- Aisinn\n",
            "- Bisin\n",
            "- Caisin\n",
            "- Disin\n",
            "- Eisii\n",
            "\n",
            "Époch 46 : La perte de validation a diminué à 2.5296. Modèle sauvegardé.\n",
            "Précision de validation : 0.2500\n",
            "Prénoms générés :\n",
            "- Aales\n",
            "- Balas\n",
            "- Calas\n",
            "- Dales\n",
            "- Eales\n",
            "\n",
            "Époch 51 : La perte de validation a diminué à 2.3714. Modèle sauvegardé.\n",
            "Précision de validation : 0.0000\n",
            "Prénoms générés :\n",
            "- Aakss\n",
            "- Bares\n",
            "- Cakss\n",
            "- Deles\n",
            "- Eakss\n",
            "\n",
            "Époch 78 : La perte de validation a diminué à 2.2355. Modèle sauvegardé.\n",
            "Précision de validation : 0.4000\n",
            "Prénoms générés :\n",
            "- Aarachihachihahachrhi\n",
            "- Baranhihacachrhihachr\n",
            "- Caranhihov\n",
            "- Danaiharachrhahacachr\n",
            "- Earachihachihahachrhe\n",
            "\n",
            "Époch 107 : La perte de validation a diminué à 1.8870. Modèle sauvegardé.\n",
            "Précision de validation : 0.3333\n",
            "Prénoms générés :\n",
            "- Aaky\n",
            "- Biky\n",
            "- Caky\n",
            "- Daky\n",
            "- Eaky\n",
            "\n",
            "Époch 162 : La perte de validation a diminué à 1.5720. Modèle sauvegardé.\n",
            "Précision de validation : 0.7143\n",
            "Prénoms générés :\n",
            "- Aatinin\n",
            "- Baninin\n",
            "- Canini\n",
            "- Datilin\n",
            "- Eanini\n",
            "\n",
            "Époch 217 : La perte de validation a diminué à 1.4817. Modèle sauvegardé.\n",
            "Précision de validation : 0.5000\n",
            "Prénoms générés :\n",
            "- Aarelov\n",
            "- Barel\n",
            "- Carel\n",
            "- Darel\n",
            "- Earel\n",
            "\n",
            "Époch 401 : La perte de validation a diminué à 1.4567. Modèle sauvegardé.\n",
            "Précision de validation : 0.5714\n",
            "Prénoms générés :\n",
            "- Aaruov\n",
            "- Barutov\n",
            "- Cikhov\n",
            "- Daruov\n",
            "- Earuovovivichov\n",
            "0m 8.23s Époch 500/200000, Perte entraînement : 2.1036, Précision entraînement : 0.4444\n",
            "Perte validation : 3.3405, Précision validation : 0.2500\n",
            "\n",
            "Époch 508 : La perte de validation a diminué à 1.4493. Modèle sauvegardé.\n",
            "Précision de validation : 0.6000\n",
            "Prénoms générés :\n",
            "- Aatlanhin\n",
            "- Balhan\n",
            "- Calhan\n",
            "- Dalhanh\n",
            "- Ealhan\n",
            "\n",
            "Époch 705 : La perte de validation a diminué à 1.3439. Modèle sauvegardé.\n",
            "Précision de validation : 0.7500\n",
            "Prénoms générés :\n",
            "- Aastyog\n",
            "- Basovoi\n",
            "- Castu\n",
            "- Dastuog\n",
            "- Eastyaizhov\n",
            "\n",
            "Époch 766 : La perte de validation a diminué à 1.2051. Modèle sauvegardé.\n",
            "Précision de validation : 0.6250\n",
            "Prénoms générés :\n",
            "- Aarichev\n",
            "- Bagulilich\n",
            "- Cukovoch\n",
            "- Darichev\n",
            "- Eagukil\n",
            "0m 16.64s Époch 1000/200000, Perte entraînement : 2.3470, Précision entraînement : 0.2857\n",
            "Perte validation : 2.7176, Précision validation : 0.3333\n",
            "0m 24.91s Époch 1500/200000, Perte entraînement : 3.0645, Précision entraînement : 0.2222\n",
            "Perte validation : 2.8970, Précision validation : 0.4545\n",
            "\n",
            "Époch 1864 : La perte de validation a diminué à 1.1631. Modèle sauvegardé.\n",
            "Précision de validation : 0.5000\n",
            "Prénoms générés :\n",
            "- Aagukev\n",
            "- Bagukov\n",
            "- Cagukov\n",
            "- Dagovov\n",
            "- Eagukov\n",
            "\n",
            "Époch 1946 : La perte de validation a diminué à 0.8709. Modèle sauvegardé.\n",
            "Précision de validation : 0.7500\n",
            "Prénoms générés :\n",
            "- Aankov\n",
            "- Bankov\n",
            "- Cankin\n",
            "- Dankov\n",
            "- Eankov\n",
            "0m 32.66s Époch 2000/200000, Perte entraînement : 2.9074, Précision entraînement : 0.2000\n",
            "Perte validation : 2.3705, Précision validation : 0.3333\n",
            "\n",
            "Époch 2113 : La perte de validation a diminué à 0.8665. Modèle sauvegardé.\n",
            "Précision de validation : 0.7000\n",
            "Prénoms générés :\n",
            "- Aalemin\n",
            "- Balomov\n",
            "- Calomov\n",
            "- Dantchevnov\n",
            "- Ealomov\n",
            "0m 40.91s Époch 2500/200000, Perte entraînement : 2.5474, Précision entraînement : 0.3333\n",
            "Perte validation : 3.8697, Précision validation : 0.0000\n",
            "0m 49.16s Époch 3000/200000, Perte entraînement : 3.2716, Précision entraînement : 0.1250\n",
            "Perte validation : 3.3761, Précision validation : 0.3000\n",
            "\n",
            "Époch 3472 : La perte de validation a diminué à 0.6725. Modèle sauvegardé.\n",
            "Précision de validation : 0.8750\n",
            "Prénoms générés :\n",
            "- Aovtin\n",
            "- Battin\n",
            "- Covshy\n",
            "- Dovtin\n",
            "- Einoih\n",
            "0m 56.88s Époch 3500/200000, Perte entraînement : 2.2861, Précision entraînement : 0.5556\n",
            "Perte validation : 3.1387, Précision validation : 0.2222\n",
            "1m 5.06s Époch 4000/200000, Perte entraînement : 3.8904, Précision entraînement : 0.2500\n",
            "Perte validation : 2.7352, Précision validation : 0.2222\n",
            "1m 13.00s Époch 4500/200000, Perte entraînement : 2.9739, Précision entraînement : 0.2500\n",
            "Perte validation : 1.5490, Précision validation : 0.3750\n",
            "1m 20.57s Époch 5000/200000, Perte entraînement : 3.5510, Précision entraînement : 0.2500\n",
            "Perte validation : 3.8471, Précision validation : 0.1250\n",
            "1m 28.83s Époch 5500/200000, Perte entraînement : 2.2361, Précision entraînement : 0.4000\n",
            "Perte validation : 2.0115, Précision validation : 0.5556\n",
            "1m 37.15s Époch 6000/200000, Perte entraînement : 3.4511, Précision entraînement : 0.1538\n",
            "Perte validation : 2.2553, Précision validation : 0.1250\n",
            "1m 44.53s Époch 6500/200000, Perte entraînement : 3.7272, Précision entraînement : 0.0000\n",
            "Perte validation : 2.5916, Précision validation : 0.1250\n",
            "1m 52.69s Époch 7000/200000, Perte entraînement : 2.6766, Précision entraînement : 0.2500\n",
            "Perte validation : 2.3032, Précision validation : 0.3750\n",
            "2m 0.78s Époch 7500/200000, Perte entraînement : 2.1078, Précision entraînement : 0.5000\n",
            "Perte validation : 3.3698, Précision validation : 0.3333\n",
            "2m 8.49s Époch 8000/200000, Perte entraînement : 1.8643, Précision entraînement : 0.4000\n",
            "Perte validation : 2.0981, Précision validation : 0.5000\n",
            "2m 16.67s Époch 8500/200000, Perte entraînement : 2.9716, Précision entraînement : 0.3333\n",
            "Perte validation : 3.5062, Précision validation : 0.1818\n",
            "2m 25.65s Époch 9000/200000, Perte entraînement : 2.3210, Précision entraînement : 0.3636\n",
            "Perte validation : 2.1447, Précision validation : 0.5000\n",
            "2m 33.51s Époch 9500/200000, Perte entraînement : 4.0910, Précision entraînement : 0.2500\n",
            "Perte validation : 2.6039, Précision validation : 0.2857\n",
            "2m 41.71s Époch 10000/200000, Perte entraînement : 2.5014, Précision entraînement : 0.3333\n",
            "Perte validation : 3.9805, Précision validation : 0.4000\n",
            "2m 49.63s Époch 10500/200000, Perte entraînement : 2.9120, Précision entraînement : 0.1250\n",
            "Perte validation : 3.3686, Précision validation : 0.2857\n",
            "2m 57.69s Époch 11000/200000, Perte entraînement : 3.2464, Précision entraînement : 0.3000\n",
            "Perte validation : 2.6793, Précision validation : 0.2000\n",
            "3m 5.83s Époch 11500/200000, Perte entraînement : 2.2091, Précision entraînement : 0.4286\n",
            "Perte validation : 3.2814, Précision validation : 0.2000\n",
            "3m 13.59s Époch 12000/200000, Perte entraînement : 2.0834, Précision entraînement : 0.5714\n",
            "Perte validation : 2.1513, Précision validation : 0.5714\n",
            "3m 21.64s Époch 12500/200000, Perte entraînement : 1.5548, Précision entraînement : 0.6250\n",
            "Perte validation : 2.8164, Précision validation : 0.3000\n",
            "3m 29.89s Époch 13000/200000, Perte entraînement : 2.7681, Précision entraînement : 0.3636\n",
            "Perte validation : 1.1534, Précision validation : 0.5000\n",
            "3m 37.58s Époch 13500/200000, Perte entraînement : 2.4049, Précision entraînement : 0.3000\n",
            "Perte validation : 3.2578, Précision validation : 0.3333\n",
            "3m 45.89s Époch 14000/200000, Perte entraînement : 3.4830, Précision entraînement : 0.1429\n",
            "Perte validation : 4.2882, Précision validation : 0.1429\n",
            "3m 54.18s Époch 14500/200000, Perte entraînement : 3.0349, Précision entraînement : 0.1818\n",
            "Perte validation : 4.5654, Précision validation : 0.1250\n",
            "4m 1.70s Époch 15000/200000, Perte entraînement : 2.7578, Précision entraînement : 0.2500\n",
            "Perte validation : 3.7041, Précision validation : 0.1000\n",
            "4m 9.97s Époch 15500/200000, Perte entraînement : 3.2329, Précision entraînement : 0.1250\n",
            "Perte validation : 2.6636, Précision validation : 0.2857\n",
            "4m 18.32s Époch 16000/200000, Perte entraînement : 3.1318, Précision entraînement : 0.0000\n",
            "Perte validation : 3.8455, Précision validation : 0.0833\n",
            "4m 25.74s Époch 16500/200000, Perte entraînement : 3.7223, Précision entraînement : 0.4286\n",
            "Perte validation : 1.4420, Précision validation : 0.5000\n",
            "4m 33.97s Époch 17000/200000, Perte entraînement : 3.7665, Précision entraînement : 0.1667\n",
            "Perte validation : 2.8842, Précision validation : 0.2500\n",
            "4m 42.24s Époch 17500/200000, Perte entraînement : 1.9706, Précision entraînement : 0.4167\n",
            "Perte validation : 2.7956, Précision validation : 0.3333\n",
            "4m 49.97s Époch 18000/200000, Perte entraînement : 4.3248, Précision entraînement : 0.2222\n",
            "Perte validation : 3.0546, Précision validation : 0.2857\n",
            "4m 58.18s Époch 18500/200000, Perte entraînement : 1.9109, Précision entraînement : 0.6667\n",
            "Perte validation : 2.0175, Précision validation : 0.5000\n",
            "5m 6.35s Époch 19000/200000, Perte entraînement : 3.3569, Précision entraînement : 0.2000\n",
            "Perte validation : 3.0343, Précision validation : 0.2500\n",
            "5m 13.79s Époch 19500/200000, Perte entraînement : 1.8856, Précision entraînement : 0.4000\n",
            "Perte validation : 2.8846, Précision validation : 0.2500\n",
            "5m 22.00s Époch 20000/200000, Perte entraînement : 2.2802, Précision entraînement : 0.1667\n",
            "Perte validation : 2.2847, Précision validation : 0.4444\n",
            "5m 30.29s Époch 20500/200000, Perte entraînement : 2.1502, Précision entraînement : 0.4444\n",
            "Perte validation : 3.1988, Précision validation : 0.3750\n",
            "5m 37.96s Époch 21000/200000, Perte entraînement : 2.7835, Précision entraînement : 0.4444\n",
            "Perte validation : 1.8973, Précision validation : 0.4286\n",
            "5m 46.20s Époch 21500/200000, Perte entraînement : 3.5673, Précision entraînement : 0.0000\n",
            "Perte validation : 2.2595, Précision validation : 0.5000\n",
            "5m 54.54s Époch 22000/200000, Perte entraînement : 2.8662, Précision entraînement : 0.2857\n",
            "Perte validation : 2.6109, Précision validation : 0.5000\n",
            "6m 2.18s Époch 22500/200000, Perte entraînement : 1.7319, Précision entraînement : 0.2857\n",
            "Perte validation : 3.9476, Précision validation : 0.1250\n",
            "6m 10.45s Époch 23000/200000, Perte entraînement : 2.3708, Précision entraînement : 0.3000\n",
            "Perte validation : 3.4261, Précision validation : 0.3077\n",
            "6m 19.00s Époch 23500/200000, Perte entraînement : 1.5227, Précision entraînement : 0.5000\n",
            "Perte validation : 2.9200, Précision validation : 0.4000\n",
            "6m 27.05s Époch 24000/200000, Perte entraînement : 1.6932, Précision entraînement : 0.4286\n",
            "Perte validation : 2.3493, Précision validation : 0.2727\n",
            "6m 35.37s Époch 24500/200000, Perte entraînement : 3.1695, Précision entraînement : 0.1667\n",
            "Perte validation : 2.8914, Précision validation : 0.2500\n",
            "6m 42.98s Époch 25000/200000, Perte entraînement : 3.0895, Précision entraînement : 0.1818\n",
            "Perte validation : 2.7488, Précision validation : 0.3333\n",
            "6m 51.13s Époch 25500/200000, Perte entraînement : 3.0970, Précision entraînement : 0.0000\n",
            "Perte validation : 1.6423, Précision validation : 0.5000\n",
            "6m 59.27s Époch 26000/200000, Perte entraînement : 3.0775, Précision entraînement : 0.2000\n",
            "Perte validation : 3.3451, Précision validation : 0.3750\n",
            "7m 6.94s Époch 26500/200000, Perte entraînement : 2.4140, Précision entraînement : 0.2000\n",
            "Perte validation : 3.7251, Précision validation : 0.0000\n",
            "7m 14.97s Époch 27000/200000, Perte entraînement : 1.9205, Précision entraînement : 0.3636\n",
            "Perte validation : 2.7298, Précision validation : 0.4000\n",
            "7m 23.28s Époch 27500/200000, Perte entraînement : 2.1861, Précision entraînement : 0.3333\n",
            "Perte validation : 2.5841, Précision validation : 0.4286\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9d7860657db1>\u001b[0m in \u001b[0;36m<cell line: 208>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Démarrage de l'entraînement...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nGénération finale de prénoms :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9d7860657db1>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(n_epochs, train_lines, valid_lines, decoder, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Entraînement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0minput_line_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_line_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_training_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_line_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_line_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9d7860657db1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_line_tensor, target_line_tensor, decoder, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_line_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_line_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "diQ5sZo_yyG-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}