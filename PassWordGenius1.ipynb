{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMpDCXc4durZN67OKKOvX34",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olfabre/amsProjetMaster1/blob/olivier/PassWordGenius1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lcvm14H7x1xj",
        "outputId": "3d5816f5-7f4d-42d5-ab35-cbb792f34834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n",
            "CUDA AVAILABLE\n",
            "Téléchargement du fichier depuis https://olivier-fabre.com/passwordgenius/shakespeare2.txt avec Pandas...\n",
            "Fichier téléchargé et chargé avec succès.\n",
            "Longueur du fichier : 311942\n",
            "[0m 6s (20 0%) 3.5863]\n",
            "Meilleure perte améliorée : 3.5863\n",
            "[0m 10s (40 0%) 3.3197]\n",
            "Meilleure perte améliorée : 3.3197\n",
            "[0m 14s (60 0%) 3.2124]\n",
            "Meilleure perte améliorée : 3.2124\n",
            "[0m 23s (80 0%) 3.1521]\n",
            "Meilleure perte améliorée : 3.1521\n",
            "[0m 30s (100 0%) 3.1067]\n",
            "Meilleure perte améliorée : 3.1067\n",
            "[0m 35s (120 0%) 3.0679]\n",
            "Meilleure perte améliorée : 3.0679\n",
            "[0m 39s (140 0%) 3.0462]\n",
            "Meilleure perte améliorée : 3.0462\n",
            "[0m 44s (160 0%) 3.0353]\n",
            "Meilleure perte améliorée : 3.0353\n",
            "[0m 49s (180 0%) 3.0203]\n",
            "Meilleure perte améliorée : 3.0203\n",
            "[0m 54s (200 0%) 3.0021]\n",
            "Meilleure perte améliorée : 3.0021\n",
            "[0m 58s (220 0%) 2.9894]\n",
            "Meilleure perte améliorée : 2.9894\n",
            "[1m 3s (240 0%) 2.9735]\n",
            "Meilleure perte améliorée : 2.9735\n",
            "[1m 8s (260 0%) 2.9613]\n",
            "Meilleure perte améliorée : 2.9613\n",
            "[1m 12s (280 0%) 2.9509]\n",
            "Meilleure perte améliorée : 2.9509\n",
            "[1m 17s (300 0%) 2.9421]\n",
            "Meilleure perte améliorée : 2.9421\n",
            "[1m 22s (320 0%) 2.9359]\n",
            "Meilleure perte améliorée : 2.9359\n",
            "[1m 26s (340 0%) 2.9261]\n",
            "Meilleure perte améliorée : 2.9261\n",
            "[1m 31s (360 0%) 2.9200]\n",
            "Meilleure perte améliorée : 2.9200\n",
            "[1m 35s (380 0%) 2.9118]\n",
            "Meilleure perte améliorée : 2.9118\n",
            "[1m 40s (400 0%) 2.9075]\n",
            "Meilleure perte améliorée : 2.9075\n",
            "[1m 45s (420 0%) 2.9069]\n",
            "Meilleure perte améliorée : 2.9069\n",
            "[1m 49s (440 0%) 2.9013]\n",
            "Meilleure perte améliorée : 2.9013\n",
            "[1m 53s (460 0%) 2.8970]\n",
            "Meilleure perte améliorée : 2.8970\n",
            "[1m 58s (480 0%) 2.8907]\n",
            "Meilleure perte améliorée : 2.8907\n",
            "[2m 3s (500 0%) 2.8925]\n",
            "[2m 8s (520 0%) 2.8920]\n",
            "[2m 12s (540 0%) 2.8914]\n",
            "[2m 16s (560 0%) 2.8944]\n",
            "[2m 21s (580 0%) 2.8959]\n",
            "[2m 26s (600 0%) 2.8974]\n",
            "[2m 30s (620 0%) 2.8970]\n",
            "[2m 35s (640 0%) 2.8979]\n",
            "[2m 39s (660 0%) 2.8988]\n",
            "[2m 44s (680 0%) 2.8975]\n",
            "[2m 48s (700 0%) 2.8960]\n",
            "[2m 53s (720 0%) 2.8928]\n",
            "[2m 58s (740 0%) 2.8916]\n",
            "[3m 2s (760 0%) 2.8905]\n",
            "Meilleure perte améliorée : 2.8905\n",
            "[3m 6s (780 0%) 2.8878]\n",
            "Meilleure perte améliorée : 2.8878\n",
            "[3m 11s (800 0%) 2.8868]\n",
            "Meilleure perte améliorée : 2.8868\n",
            "[3m 15s (820 0%) 2.8851]\n",
            "Meilleure perte améliorée : 2.8851\n",
            "[3m 20s (840 0%) 2.8840]\n",
            "Meilleure perte améliorée : 2.8840\n",
            "[3m 25s (860 0%) 2.8802]\n",
            "Meilleure perte améliorée : 2.8802\n",
            "[3m 29s (880 0%) 2.8798]\n",
            "Meilleure perte améliorée : 2.8798\n",
            "[3m 34s (900 0%) 2.8793]\n",
            "Meilleure perte améliorée : 2.8793\n",
            "[3m 38s (920 0%) 2.8776]\n",
            "Meilleure perte améliorée : 2.8776\n",
            "[3m 42s (940 0%) 2.8768]\n",
            "Meilleure perte améliorée : 2.8768\n",
            "[3m 48s (960 0%) 2.8742]\n",
            "Meilleure perte améliorée : 2.8742\n",
            "[3m 52s (980 0%) 2.8743]\n",
            "[3m 56s (1000 0%) 2.8744]\n",
            "[4m 1s (1020 0%) 2.8730]\n",
            "Meilleure perte améliorée : 2.8730\n",
            "[4m 5s (1040 0%) 2.8734]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-12464471df0c>\u001b[0m in \u001b[0;36m<cell line: 160>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Entraînement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Évaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-12464471df0c>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(n_epochs, file, chunk_count)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-12464471df0c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inp, target)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-12464471df0c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1741\u001b[0;31m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1742\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import unidecode\n",
        "except ModuleNotFoundError:\n",
        "    !pip install unidecode\n",
        "    import unidecode\n",
        "import string\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Configurer l'appareil (CPU ou GPU)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print('CUDA AVAILABLE')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('ONLY CPU AVAILABLE')\n",
        "\n",
        "# Variables globales\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "chunk_len = 13\n",
        "\n",
        "# Paramètres de configuration\n",
        "n_epochs = 200000\n",
        "print_every = 10\n",
        "hidden_size = 512\n",
        "n_layers = 3\n",
        "lr = 0.005\n",
        "\n",
        "# Téléchargement avec Pandas\n",
        "def download_file_with_pandas(url):\n",
        "    print(f\"Téléchargement du fichier depuis {url} avec Pandas...\")\n",
        "    try:\n",
        "        # Lire tout le fichier texte en DataFrame\n",
        "        data = pd.read_table(url, header=None, quoting=3)  # Lecture ligne par ligne\n",
        "        text = \"\\n\".join(data[0].tolist())  # Combiner toutes les lignes en une seule chaîne\n",
        "        print(\"Fichier téléchargé et chargé avec succès.\")\n",
        "        return unidecode.unidecode(text)  # Nettoyage des caractères accentués\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors du téléchargement : {e}\")\n",
        "        exit(1)\n",
        "\n",
        "# Fonctions d'entraînement et d'évaluation\n",
        "def random_chunk(file):\n",
        "    start_index = random.randint(0, len(file) - chunk_len - 1)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)\n",
        "\n",
        "def random_training_set(file):\n",
        "    chunk = random_chunk(file)\n",
        "    inp = char_tensor(chunk[:-1]).to(device)\n",
        "    target = char_tensor(chunk[1:]).to(device)\n",
        "    return inp, target\n",
        "\n",
        "def evaluate(decoder, prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = decoder.init_hidden()\n",
        "    prime_input = char_tensor(prime_str).to(device)\n",
        "    predicted = prime_str\n",
        "\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = decoder(prime_input[p], hidden)\n",
        "    inp = prime_input[-1]\n",
        "\n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor(predicted_char).to(device)\n",
        "\n",
        "    return predicted\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden()\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "    for c in range(inp.size(0)):\n",
        "        output, hidden = decoder(inp[c], hidden)\n",
        "        loss += criterion(output, target[c].unsqueeze(0))\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / chunk_len\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size, device=device))\n",
        "\n",
        "def training(n_epochs, file, chunk_count=10):\n",
        "    start = time.time()\n",
        "    loss_avg = 0\n",
        "    best_loss = float(\"inf\")\n",
        "    print_every = n_epochs // 10000\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        losses = []\n",
        "        for _ in range(chunk_count):\n",
        "            loss = train(*random_training_set(file))\n",
        "            losses.append(loss)\n",
        "\n",
        "        loss_avg += sum(losses) / chunk_count\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss_avg / epoch))\n",
        "\n",
        "            if best_loss > (loss_avg / epoch):\n",
        "                best_loss = loss_avg / epoch\n",
        "                print(f\"Meilleure perte améliorée : {best_loss:.4f}\")\n",
        "\n",
        "def evaluating(decoder, length):\n",
        "    print(\"\\nMode Évaluation :\")\n",
        "    try:\n",
        "        while True:\n",
        "            input1 = input(\"Entrez un début de texte : \")\n",
        "            if len(input1) > 0:\n",
        "                print(evaluate(decoder, prime_str=input1, predict_len=length, temperature=0.8))\n",
        "            else:\n",
        "                print(\"Entrée invalide.\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nÉvaluation terminée.\")\n",
        "\n",
        "# Exécution principale\n",
        "if __name__ == '__main__':\n",
        "    file_url = \"https://olivier-fabre.com/passwordgenius/shakespeare2.txt\"\n",
        "    file = download_file_with_pandas(file_url)\n",
        "    file_len = len(file)\n",
        "\n",
        "    print(\"Longueur du fichier :\", file_len)\n",
        "\n",
        "    decoder = RNN(n_characters, hidden_size, n_characters, n_layers).to(device)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Entraînement\n",
        "    decoder.train()\n",
        "    training(n_epochs, file)\n",
        "\n",
        "    # Évaluation\n",
        "    decoder.eval()\n",
        "    evaluating(decoder, length=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqUgdy6O0WUi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}