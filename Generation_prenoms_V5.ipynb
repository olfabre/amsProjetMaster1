{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olfabre/amsProjetMaster1/blob/olivier/Generation_prenoms_V5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Vérification GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Appareil utilisé : {device}\")\n",
        "\n",
        "# Téléchargement des données\n",
        "url = \"https://olivier-fabre.com/passwordgenius/russian.txt\"\n",
        "data_dir = \"data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "data_path = os.path.join(data_dir, \"russian.txt\")\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "    print(\"Téléchargement des données...\")\n",
        "    response = requests.get(url)\n",
        "    with open(data_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(response.text)\n",
        "\n",
        "# Chargement des données\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in s if c in (string.ascii_letters + \" .,;'-\")\n",
        "    )\n",
        "\n",
        "def read_lines(filename):\n",
        "    with open(filename, encoding='utf-8') as f:\n",
        "        return [unicode_to_ascii(line.strip().lower()) for line in f]\n",
        "\n",
        "lines = read_lines(data_path)\n",
        "print(f\"Nombre de prénoms : {len(lines)}\")\n",
        "\n",
        "# Division des données\n",
        "random.shuffle(lines)\n",
        "train_split = int(0.7 * len(lines))\n",
        "valid_split = int(0.2 * len(lines))\n",
        "train_lines = lines[:train_split]\n",
        "valid_lines = lines[train_split:train_split + valid_split]\n",
        "test_lines = lines[train_split + valid_split:]\n",
        "print(f\"Ensemble d'entraînement : {len(train_lines)}, Validation : {len(valid_lines)}, Test : {len(test_lines)}\")\n",
        "\n",
        "# Paramètres globaux\n",
        "all_letters = string.ascii_letters + \" .,;'-\"\n",
        "n_letters = len(all_letters) + 1  # EOS marker\n",
        "hidden_size = 256\n",
        "n_layers = 3\n",
        "lr = 0.003\n",
        "bidirectional = True\n",
        "max_length = 20\n",
        "n_epochs = 200000\n",
        "\n",
        "# Fonctions utilitaires\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_letters.index(string[c])\n",
        "    return tensor\n",
        "\n",
        "def input_tensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li in range(len(line)):\n",
        "        letter = line[li]\n",
        "        tensor[li][0][all_letters.find(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "def target_tensor(line):\n",
        "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
        "    letter_indexes.append(n_letters - 1)  # EOS\n",
        "    return torch.LongTensor(letter_indexes)\n",
        "\n",
        "def random_training_example(lines):\n",
        "    line = random.choice(lines)\n",
        "    input_line_tensor = input_tensor(line)\n",
        "    target_line_tensor = target_tensor(line)\n",
        "    return input_line_tensor, target_line_tensor\n",
        "\n",
        "# Fonction pour afficher le temps écoulé\n",
        "def time_since(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f\"{m}m {s:.2f}s\"\n",
        "\n",
        "# Définition du modèle\n",
        "class RNNLight(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNNLight, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 2 if self.bidirectional else 1\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=input_size, hidden_size=hidden_size,\n",
        "            num_layers=n_layers, bidirectional=self.bidirectional, batch_first=True\n",
        "        )\n",
        "        self.out = nn.Linear(self.num_directions * hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        _, hidden = self.rnn(input.unsqueeze(0), hidden)\n",
        "        hidden_concat = hidden if not self.bidirectional else torch.cat((hidden[0], hidden[1]), 1)\n",
        "        output = self.out(hidden_concat)\n",
        "        output = self.dropout(output)\n",
        "        return self.softmax(output), hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.num_directions * n_layers, 1, self.hidden_size, device=device)\n",
        "\n",
        "# Fonction pour générer des prénoms\n",
        "def generate_prenoms(decoder, start_letters=\"ABCDE\"):\n",
        "    print(\"\\nPrénoms générés :\")\n",
        "    for letter in start_letters:\n",
        "        print(f\"- {sample(decoder, letter)}\")\n",
        "\n",
        "def sample(decoder, start_letter=\"A\"):\n",
        "    with torch.no_grad():\n",
        "        hidden = decoder.init_hidden()\n",
        "        input = input_tensor(start_letter)\n",
        "        output_name = start_letter\n",
        "        for _ in range(max_length):\n",
        "            output, hidden = decoder(input[0].to(device), hidden.to(device))\n",
        "            topi = output.topk(1)[1][0][0]\n",
        "            if topi == n_letters - 1:\n",
        "                break\n",
        "            else:\n",
        "                letter = all_letters[topi]\n",
        "                output_name += letter\n",
        "            input = input_tensor(letter)\n",
        "        return output_name\n",
        "\n",
        "# Entraînement avec sauvegarde\n",
        "def train(input_line_tensor, target_line_tensor, decoder, decoder_optimizer, criterion):\n",
        "    target_line_tensor = target_line_tensor.to(device)\n",
        "    hidden = decoder.init_hidden().to(device)\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "    correct = 0  # Précision\n",
        "    total = target_line_tensor.size(0)\n",
        "\n",
        "    for i in range(input_line_tensor.size(0)):\n",
        "        input_tensor = input_line_tensor[i].to(device)\n",
        "        target_tensor = target_line_tensor[i].unsqueeze(0).to(device)\n",
        "        output, hidden = decoder(input_tensor, hidden.detach())\n",
        "        l = criterion(output, target_tensor)\n",
        "        loss += l\n",
        "\n",
        "        # Calcul de la précision\n",
        "        predicted = output.topk(1)[1][0][0]\n",
        "        correct += (predicted == target_tensor[0]).item()\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return loss.item() / input_line_tensor.size(0), accuracy\n",
        "\n",
        "def validation(input_line_tensor, target_line_tensor, decoder, criterion):\n",
        "    with torch.no_grad():\n",
        "        target_line_tensor = target_line_tensor.to(device)\n",
        "        hidden = decoder.init_hidden().to(device)\n",
        "        loss = 0\n",
        "        correct = 0\n",
        "        total = target_line_tensor.size(0)\n",
        "\n",
        "        for i in range(input_line_tensor.size(0)):\n",
        "            input_tensor = input_line_tensor[i].to(device)\n",
        "            target_tensor = target_line_tensor[i].unsqueeze(0).to(device)\n",
        "            output, hidden = decoder(input_tensor, hidden.detach())\n",
        "            l = criterion(output, target_tensor)\n",
        "            loss += l\n",
        "\n",
        "            # Calcul de la précision\n",
        "            predicted = output.topk(1)[1][0][0]\n",
        "            correct += (predicted == target_tensor[0]).item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        return loss.item() / input_line_tensor.size(0), accuracy\n",
        "\n",
        "# Ajustement dynamique du taux d'apprentissage\n",
        "def adjust_learning_rate(optimizer, epoch, decay_rate=0.5, step=20000):\n",
        "    if epoch % step == 0 and epoch > 0:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] *= decay_rate\n",
        "            print(f\"Taux d'apprentissage ajusté à : {param_group['lr']}\")\n",
        "\n",
        "# Fonction principale d'entraînement\n",
        "def training(n_epochs, train_lines, valid_lines, decoder, decoder_optimizer, criterion):\n",
        "    print(\"\\n-----------\\n|  ENTRAÎNEMENT  |\\n-----------\\n\")\n",
        "    start = time.time()\n",
        "    best_loss = float(\"inf\")\n",
        "    model_path = \"best_model_generation_prenom.pth\"\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        adjust_learning_rate(decoder_optimizer, epoch)\n",
        "\n",
        "        input_line_tensor, target_line_tensor = random_training_example(train_lines)\n",
        "        train_loss, train_acc = train(input_line_tensor, target_line_tensor, decoder, decoder_optimizer, criterion)\n",
        "\n",
        "        input_line_tensor, target_line_tensor = random_training_example(valid_lines)\n",
        "        val_loss, val_acc = validation(input_line_tensor, target_line_tensor, decoder, criterion)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save(decoder.state_dict(), model_path)\n",
        "            print(f\"\\nÉpoch {epoch} : La perte de validation a diminué à {best_loss:.4f}. Modèle sauvegardé.\")\n",
        "            print(f\"Précision validation : {val_acc:.4f}\")\n",
        "            generate_prenoms(decoder)\n",
        "\n",
        "        if epoch % 500 == 0 or epoch == 1:\n",
        "            print(f\"{time_since(start)} Époch {epoch}/{n_epochs}, Perte entraînement : {train_loss:.4f}, Précision entraînement : {train_acc:.4f}\")\n",
        "            print(f\"Perte validation : {val_loss:.4f}, Précision validation : {val_acc:.4f}\")\n",
        "\n",
        "# Exécution principale\n",
        "if __name__ == \"__main__\":\n",
        "    decoder = RNNLight(n_letters, hidden_size, n_letters).to(device)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"Démarrage de l'entraînement...\")\n",
        "    training(n_epochs, train_lines, valid_lines, decoder, decoder_optimizer, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-OY1QlZ5sDGl",
        "outputId": "f5720d39-c755-4de4-bc35-233da9822c27"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appareil utilisé : cuda:0\n",
            "Nombre de prénoms : 9408\n",
            "Ensemble d'entraînement : 6585, Validation : 1881, Test : 942\n",
            "Démarrage de l'entraînement...\n",
            "\n",
            "-----------\n",
            "|  ENTRAÎNEMENT  |\n",
            "-----------\n",
            "\n",
            "\n",
            "Époch 1 : La perte de validation a diminué à 4.0014. Modèle sauvegardé.\n",
            "Précision validation : 0.1429\n",
            "\n",
            "Prénoms générés :\n",
            "- Aiiiiiiiiiiiiiiiiiiih\n",
            "- Birochkiiiiiiiiiiiiii\n",
            "- Crochkiiiiiihoihkiiro\n",
            "- Drrrochkiiiiiiiihoihk\n",
            "- Eiiiirochkiiiiiiiiiii\n",
            "0m 0.16s Époch 1/200000, Perte entraînement : 4.0699, Précision entraînement : 0.0000\n",
            "Perte validation : 4.0014, Précision validation : 0.1429\n",
            "\n",
            "Époch 2 : La perte de validation a diminué à 3.7901. Modèle sauvegardé.\n",
            "Précision validation : 0.2000\n",
            "\n",
            "Prénoms générés :\n",
            "- Averoiiiiiiiiiiiiiiii\n",
            "- Biieiiiieiiiiiiiiiiii\n",
            "- Cveroiiiiiiiiiiieiiii\n",
            "- Diiiiiieiiiiviiiiiiii\n",
            "- Eoiieiiiiiiiiiioiiiii\n",
            "\n",
            "Époch 3 : La perte de validation a diminué à 3.7305. Modèle sauvegardé.\n",
            "Précision validation : 0.1429\n",
            "\n",
            "Prénoms générés :\n",
            "- Aiiiieiiiiiikikiiiiii\n",
            "- Bveroiiiiiiiiiiiiiiii\n",
            "- Ciiiiiiieiikveiievekk\n",
            "- Dveroiiiiiiiiiiiiiiii\n",
            "- Eiiiiiiiiiiiikiikiiii\n",
            "\n",
            "Époch 4 : La perte de validation a diminué à 3.5634. Modèle sauvegardé.\n",
            "Précision validation : 0.1667\n",
            "\n",
            "Prénoms générés :\n",
            "- Aiikkkkkkekkkkkkkkkkk\n",
            "- Bvekkkkkkkekkkkkkkkkk\n",
            "- Cvekkkkkkkkkkkkkvkekk\n",
            "- Dvekkkkkkkkkkkkkkkvkk\n",
            "- Eokikkkkkkkkkkkkkkkkk\n",
            "\n",
            "Époch 5 : La perte de validation a diminué à 3.2844. Modèle sauvegardé.\n",
            "Précision validation : 0.0000\n",
            "\n",
            "Prénoms générés :\n",
            "- Avekekkkkkkkkkkkkekkk\n",
            "- Bvekkkkkkkkkkkkkkkkkk\n",
            "- Cvekkkkkkkkkkkkkekkkk\n",
            "- Dvekkkkkkkkkkkkkkkkkk\n",
            "- Eeekkkkkkkkkkkekkkkkk\n",
            "\n",
            "Époch 6 : La perte de validation a diminué à 2.9419. Modèle sauvegardé.\n",
            "Précision validation : 0.2000\n",
            "\n",
            "Prénoms générés :\n",
            "- Aeekk\n",
            "- Beekk\n",
            "- Ceekk\n",
            "- Dvekk\n",
            "- Eeekk\n",
            "\n",
            "Époch 7 : La perte de validation a diminué à 2.8840. Modèle sauvegardé.\n",
            "Précision validation : 0.1667\n",
            "\n",
            "Prénoms générés :\n",
            "- Aee\n",
            "- Bee\n",
            "- Cee\n",
            "- Dee\n",
            "- Eei\n",
            "\n",
            "Époch 22 : La perte de validation a diminué à 2.6512. Modèle sauvegardé.\n",
            "Précision validation : 0.2500\n",
            "\n",
            "Prénoms générés :\n",
            "- Aiia\n",
            "- Biaa\n",
            "- Cia\n",
            "- Diia\n",
            "- Eii\n",
            "\n",
            "Époch 29 : La perte de validation a diminué à 2.5683. Modèle sauvegardé.\n",
            "Précision validation : 0.2500\n",
            "\n",
            "Prénoms générés :\n",
            "- Aininnnn\n",
            "- Biinisnnn\n",
            "- Ciirnnnn\n",
            "- Dininnnn\n",
            "- Eiinnnnn\n",
            "\n",
            "Époch 33 : La perte de validation a diminué à 2.3980. Modèle sauvegardé.\n",
            "Précision validation : 0.2500\n",
            "\n",
            "Prénoms générés :\n",
            "- Airnv\n",
            "- Binnvn\n",
            "- Cirov\n",
            "- Dinrv\n",
            "- Einnv\n",
            "\n",
            "Époch 48 : La perte de validation a diminué à 2.2122. Modèle sauvegardé.\n",
            "Précision validation : 0.3636\n",
            "\n",
            "Prénoms générés :\n",
            "- Aeooon\n",
            "- Beaoon\n",
            "- Coaoon\n",
            "- Deaoonov\n",
            "- Eeooin\n",
            "\n",
            "Époch 70 : La perte de validation a diminué à 1.5577. Modèle sauvegardé.\n",
            "Précision validation : 0.7143\n",
            "\n",
            "Prénoms générés :\n",
            "- Aarhanh\n",
            "- Baran\n",
            "- Caran\n",
            "- Daran\n",
            "- Earanov\n",
            "\n",
            "Époch 178 : La perte de validation a diminué à 1.3405. Modèle sauvegardé.\n",
            "Précision validation : 0.6667\n",
            "\n",
            "Prénoms générés :\n",
            "- Aarov\n",
            "- Barov\n",
            "- Carov\n",
            "- Darov\n",
            "- Earov\n",
            "\n",
            "Époch 222 : La perte de validation a diminué à 0.8137. Modèle sauvegardé.\n",
            "Précision validation : 0.6000\n",
            "\n",
            "Prénoms générés :\n",
            "- Aalov\n",
            "- Barov\n",
            "- Calovikov\n",
            "- Dalikov\n",
            "- Ealov\n",
            "0m 11.91s Époch 500/200000, Perte entraînement : 3.0452, Précision entraînement : 0.1429\n",
            "Perte validation : 1.8923, Précision validation : 0.5714\n",
            "0m 22.97s Époch 1000/200000, Perte entraînement : 3.3416, Précision entraînement : 0.0000\n",
            "Perte validation : 2.3716, Précision validation : 0.3333\n",
            "\n",
            "Époch 1001 : La perte de validation a diminué à 0.7823. Modèle sauvegardé.\n",
            "Précision validation : 0.6667\n",
            "\n",
            "Prénoms générés :\n",
            "- Aanshan\n",
            "- Baevshy\n",
            "- Canich\n",
            "- Danich\n",
            "- Eanich\n",
            "0m 33.44s Époch 1500/200000, Perte entraînement : 3.1245, Précision entraînement : 0.2000\n",
            "Perte validation : 2.9532, Précision validation : 0.3333\n",
            "0m 44.26s Époch 2000/200000, Perte entraînement : 3.4135, Précision entraînement : 0.1429\n",
            "Perte validation : 3.2812, Précision validation : 0.0000\n",
            "0m 55.30s Époch 2500/200000, Perte entraînement : 1.3427, Précision entraînement : 0.5556\n",
            "Perte validation : 2.6306, Précision validation : 0.5000\n",
            "1m 6.33s Époch 3000/200000, Perte entraînement : 3.3862, Précision entraînement : 0.3333\n",
            "Perte validation : 2.5965, Précision validation : 0.5000\n",
            "1m 17.53s Époch 3500/200000, Perte entraînement : 3.1201, Précision entraînement : 0.1250\n",
            "Perte validation : 2.6928, Précision validation : 0.3750\n",
            "1m 29.39s Époch 4000/200000, Perte entraînement : 3.6277, Précision entraînement : 0.2222\n",
            "Perte validation : 2.9920, Précision validation : 0.1250\n",
            "1m 40.64s Époch 4500/200000, Perte entraînement : 2.6648, Précision entraînement : 0.4286\n",
            "Perte validation : 2.6407, Précision validation : 0.2500\n",
            "1m 51.69s Époch 5000/200000, Perte entraînement : 2.3019, Précision entraînement : 0.1667\n",
            "Perte validation : 2.7394, Précision validation : 0.3333\n",
            "2m 2.89s Époch 5500/200000, Perte entraînement : 2.6955, Précision entraînement : 0.2857\n",
            "Perte validation : 3.3422, Précision validation : 0.1000\n",
            "\n",
            "Époch 5902 : La perte de validation a diminué à 0.2858. Modèle sauvegardé.\n",
            "Précision validation : 1.0000\n",
            "\n",
            "Prénoms générés :\n",
            "- Aerov\n",
            "- Bev\n",
            "- Cerov\n",
            "- Dikov\n",
            "- Eikov\n",
            "2m 14.02s Époch 6000/200000, Perte entraînement : 2.5164, Précision entraînement : 0.6000\n",
            "Perte validation : 3.2513, Précision validation : 0.2222\n",
            "2m 24.70s Époch 6500/200000, Perte entraînement : 1.8339, Précision entraînement : 0.2857\n",
            "Perte validation : 2.1739, Précision validation : 0.4286\n",
            "2m 35.10s Époch 7000/200000, Perte entraînement : 4.8105, Précision entraînement : 0.0000\n",
            "Perte validation : 3.7234, Précision validation : 0.1667\n",
            "2m 46.30s Époch 7500/200000, Perte entraînement : 2.0898, Précision entraînement : 0.5556\n",
            "Perte validation : 3.0377, Précision validation : 0.2500\n",
            "2m 57.54s Époch 8000/200000, Perte entraînement : 2.3121, Précision entraînement : 0.4286\n",
            "Perte validation : 3.6755, Précision validation : 0.0000\n",
            "3m 8.68s Époch 8500/200000, Perte entraînement : 2.6483, Précision entraînement : 0.0000\n",
            "Perte validation : 3.7159, Précision validation : 0.1429\n",
            "3m 19.70s Époch 9000/200000, Perte entraînement : 3.1556, Précision entraînement : 0.1667\n",
            "Perte validation : 2.7645, Précision validation : 0.2000\n",
            "3m 30.61s Époch 9500/200000, Perte entraînement : 2.6347, Précision entraînement : 0.2000\n",
            "Perte validation : 2.0823, Précision validation : 0.4286\n",
            "3m 41.49s Époch 10000/200000, Perte entraînement : 2.2788, Précision entraînement : 0.4545\n",
            "Perte validation : 3.0481, Précision validation : 0.1250\n",
            "3m 52.32s Époch 10500/200000, Perte entraînement : 3.0917, Précision entraînement : 0.2857\n",
            "Perte validation : 3.7256, Précision validation : 0.2000\n",
            "4m 3.16s Époch 11000/200000, Perte entraînement : 3.3302, Précision entraînement : 0.1429\n",
            "Perte validation : 2.3369, Précision validation : 0.3333\n",
            "4m 13.83s Époch 11500/200000, Perte entraînement : 2.8139, Précision entraînement : 0.2222\n",
            "Perte validation : 2.1550, Précision validation : 0.2222\n",
            "4m 24.50s Époch 12000/200000, Perte entraînement : 2.7581, Précision entraînement : 0.2500\n",
            "Perte validation : 3.6054, Précision validation : 0.3000\n",
            "4m 35.60s Époch 12500/200000, Perte entraînement : 3.3440, Précision entraînement : 0.2727\n",
            "Perte validation : 2.9426, Précision validation : 0.4444\n",
            "4m 46.62s Époch 13000/200000, Perte entraînement : 2.6753, Précision entraînement : 0.1667\n",
            "Perte validation : 2.2823, Précision validation : 0.5556\n",
            "4m 57.48s Époch 13500/200000, Perte entraînement : 3.3219, Précision entraînement : 0.3333\n",
            "Perte validation : 3.6655, Précision validation : 0.3000\n",
            "5m 8.58s Époch 14000/200000, Perte entraînement : 3.0779, Précision entraînement : 0.2500\n",
            "Perte validation : 3.1298, Précision validation : 0.1429\n",
            "5m 20.15s Époch 14500/200000, Perte entraînement : 2.0371, Précision entraînement : 0.5000\n",
            "Perte validation : 2.6740, Précision validation : 0.2500\n",
            "5m 31.01s Époch 15000/200000, Perte entraînement : 2.7538, Précision entraînement : 0.1818\n",
            "Perte validation : 3.3232, Précision validation : 0.2500\n",
            "5m 42.09s Époch 15500/200000, Perte entraînement : 3.3337, Précision entraînement : 0.3333\n",
            "Perte validation : 2.0949, Précision validation : 0.5000\n",
            "5m 53.07s Époch 16000/200000, Perte entraînement : 3.0336, Précision entraînement : 0.2857\n",
            "Perte validation : 2.5769, Précision validation : 0.4286\n",
            "6m 3.40s Époch 16500/200000, Perte entraînement : 1.5401, Précision entraînement : 0.5714\n",
            "Perte validation : 2.3236, Précision validation : 0.3333\n",
            "6m 14.22s Époch 17000/200000, Perte entraînement : 1.6842, Précision entraînement : 0.4000\n",
            "Perte validation : 2.7025, Précision validation : 0.2857\n",
            "6m 25.18s Époch 17500/200000, Perte entraînement : 1.4540, Précision entraînement : 0.4444\n",
            "Perte validation : 2.5015, Précision validation : 0.4286\n",
            "6m 36.19s Époch 18000/200000, Perte entraînement : 1.9938, Précision entraînement : 0.5000\n",
            "Perte validation : 2.3372, Précision validation : 0.4000\n",
            "6m 47.28s Époch 18500/200000, Perte entraînement : 2.3890, Précision entraînement : 0.3000\n",
            "Perte validation : 3.3202, Précision validation : 0.2857\n",
            "6m 58.20s Époch 19000/200000, Perte entraînement : 3.7743, Précision entraînement : 0.0000\n",
            "Perte validation : 2.8565, Précision validation : 0.1818\n",
            "7m 9.20s Époch 19500/200000, Perte entraînement : 2.3753, Précision entraînement : 0.3750\n",
            "Perte validation : 1.8239, Précision validation : 0.4444\n",
            "Taux d'apprentissage ajusté à : 0.0015\n",
            "7m 20.34s Époch 20000/200000, Perte entraînement : 1.4296, Précision entraînement : 0.7143\n",
            "Perte validation : 2.9532, Précision validation : 0.1429\n",
            "7m 31.25s Époch 20500/200000, Perte entraînement : 2.3645, Précision entraînement : 0.4444\n",
            "Perte validation : 2.6257, Précision validation : 0.4286\n",
            "7m 42.28s Époch 21000/200000, Perte entraînement : 3.0200, Précision entraînement : 0.2500\n",
            "Perte validation : 1.9682, Précision validation : 0.3750\n",
            "7m 52.86s Époch 21500/200000, Perte entraînement : 2.4892, Précision entraînement : 0.1250\n",
            "Perte validation : 2.7449, Précision validation : 0.3750\n",
            "8m 3.69s Époch 22000/200000, Perte entraînement : 2.4942, Précision entraînement : 0.4444\n",
            "Perte validation : 2.0623, Précision validation : 0.2500\n",
            "8m 14.66s Époch 22500/200000, Perte entraînement : 1.8383, Précision entraînement : 0.5000\n",
            "Perte validation : 1.8340, Précision validation : 0.2857\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-271daee00fea>\u001b[0m in \u001b[0;36m<cell line: 225>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Démarrage de l'entraînement...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-271daee00fea>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(n_epochs, train_lines, valid_lines, decoder, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0minput_line_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_line_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_training_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_line_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_line_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0minput_line_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_line_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_training_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-271daee00fea>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_line_tensor, target_line_tensor, decoder, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_line_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_line_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-271daee00fea>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mhidden_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "diQ5sZo_yyG-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}